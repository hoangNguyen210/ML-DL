{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZmPXYOewz5r"
   },
   "source": [
    "## THỰC HÀNH MHNC LAB 05\n",
    "\n",
    "### Nguyễn Minh Hoàng 18110095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_tn3MOWXaImA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import io\n",
    "\n",
    "from tensorflow.keras.layers import ( \n",
    "                              Input, Embedding, LSTM, Bidirectional, \n",
    "                               Dense, Dropout, BatchNormalization,GRU,\n",
    "                               GlobalAveragePooling1D)\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nM4Ic0Kkbmis"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, GRU, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0igJ7_3SMW1-",
    "outputId": "fb796afe-8f80-4ddf-f3f5-6bc0a438b2b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Label  y\n",
       "0  Go until jurong point, crazy.. Available only ...   ham  0\n",
       "1                      Ok lar... Joking wif u oni...   ham  0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam  1\n",
       "3  U dun say so early hor... U c already then say...   ham  0\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#đọc data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/AML/main/lab-04/spam_detection.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjptVMk-1dqt",
    "outputId": "a2e3098d-2cca-49e6-ff32-a3b127b7dc07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1nnAMXNeXAa",
    "outputId": "0d15cb88-dcd9-4254-c9d8-724ac8ecab90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "['go', 'until', 'jurong', 'point', ',', 'crazy..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'cine', 'there', 'got', 'amore', 'wat', '...']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "texts = df[\"Text\"].to_list()\n",
    "texts = [text.lower() for text in texts ]           # chuyển các đoạn text thành chữ thường (word embedding chỉ cho chữ thường)\n",
    "tokenized_texts = [nltk.tokenize.word_tokenize(text) for text in texts]    # tách câu thành một list các từ\n",
    "\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlAN3OpJ2Unl"
   },
   "source": [
    "Để Vectorize các câu ta sử dụng một bộ trọng số có tên là Glove do Stanford phát triển. bộ weights này sẽ biến mỗi chữ thành 1 vector có số nhiều là 50, 100, 200, hoặc 300. Số chiều càng lớn thì vector sẽ càng biểu diễn được ngữ nghĩa của một từ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzibQmpWetV7",
    "outputId": "2906d4d5-bbbf-4318-a587-8d1e67b2d861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-20 13:42:06--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-11-20 13:42:07--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-11-20 13:42:07--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip.1’\n",
      "\n",
      "glove.6B.zip.1      100%[===================>] 822.24M  5.04MB/s    in 2m 47s  \n",
      "\n",
      "2021-11-20 13:44:54 (4.93 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tải bộ weights Glove\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "od20jMkReuwn",
    "outputId": "5c2d5ede-7e6b-4937-ed07-a2b9edc004a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "#Giải Nén\n",
    "! unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K_FHeyWtewDb"
   },
   "outputs": [],
   "source": [
    "## không cần hiểu đống này lắm đâu\n",
    "def load_word_embeddings(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    vocab, matrix = [], []\n",
    "    i=0\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        vocab.append(tokens[0])\n",
    "        matrix.append(list(map(float, tokens[1:])))\n",
    "    return vocab, np.asarray(matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VdpZ46UJfsDd"
   },
   "outputs": [],
   "source": [
    "#vocab là bộ từ điển các từ có trong Glove\n",
    "#matrix chứa các vector biểu diễn các từ \n",
    "##Ta chọn bộ weighs có số chiều là 100\n",
    "vocab, matrix = load_word_embeddings(\"glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "chjAkG-ThvaU",
    "outputId": "e8d99a22-2298-4e2a-e65b-77e03e7eac19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7QifIpxftQS",
    "outputId": "8a8f05fb-6ad6-4f8e-cde8-6dbb8c4a7948"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in thử shape của matrix\n",
    "##Ta có thể thấy bộ từ điển này có 400000, mỗi từ là 1 vecotr có 100 chiều \n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dkWF1TdwfttL"
   },
   "outputs": [],
   "source": [
    "## Gán các mã\n",
    "__PADDED_INDEX__ = 0    # mã dùng cho các vị trí chỉ có tính nối dài cho cùng kích thước\n",
    "__UNKNOWN_WORD__ = 1    # mã cho những từ không có trong embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ALAcF_1pf9Ey"
   },
   "outputs": [],
   "source": [
    "# Tạo một dictionary, có nhiệm vụ là một ánh xạ từ ảnh sang mã số, mã số được bắt đầu từ 2 vì số 0 và 1 được dành cho trường hợp đặc biệt\n",
    "word_to_index = {word: index+2 for index, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O251cquWf_fF",
    "outputId": "865605c8-bebf-4053-9df8-d5607f31f3d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [-0.038194 -0.24487   0.72812  ... -0.1459    0.8278    0.27062 ]\n",
      " ...\n",
      " [ 0.36088  -0.16919  -0.32704  ...  0.27139  -0.29188   0.16109 ]\n",
      " [-0.10461  -0.5047   -0.49331  ...  0.42527  -0.5125   -0.17054 ]\n",
      " [ 0.28365  -0.6263   -0.44351  ...  0.43678  -0.82607  -0.15701 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Do do mã số được bắt đầu từ 2, nên cần thêm 2 vector vào đàu ma trận\n",
    "embedding_matrix = np.pad(matrix, ((2,0),(0,0)), mode='constant', constant_values =0.0)\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AYd_tIdbgDsd"
   },
   "outputs": [],
   "source": [
    "## Bây giờ ta sẽ chuyển data spam dection thành các mã số\n",
    "import tensorflow as tf\n",
    "\n",
    "X = []\n",
    "for text in tokenized_texts:\n",
    "    cur_text_indices = []\n",
    "    for word in text:\n",
    "        if word in word_to_index:\n",
    "            cur_text_indices.append(word_to_index[word])    ## map từ word sang index\n",
    "        else:\n",
    "            cur_text_indices.append(__UNKNOWN_WORD__)       ## gán unknown cho từ không có trong bộ glove\n",
    "    X.append(cur_text_indices)\n",
    "\n",
    "## pad data cho có cùng chiều dài\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(sequences=X,       # sequences: list các câu có độ dài không bằng nhau\n",
    "                                                  padding='post')    # vị trí pad là 'pre' (trước) hoặc 'post' (sau)\n",
    "\n",
    "y = df['y'].values   ## Label của bài toán, 0 là không phải spam, 1 là spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIwX5dIw1r14",
    "outputId": "01e57879-0e3f-4a7c-ff67-d5af13fb6ae4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Fy3sjsoZhj7X"
   },
   "outputs": [],
   "source": [
    "## Chia data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size= 0.2, random_state =0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyRVOYrIEE2F"
   },
   "source": [
    "####1. Tìm hiểu về cách dùng của GRU và chạy theo 2 cách hướng dẫn ở trên "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKme5rB_IcjR"
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mx47LfthhlhL",
    "outputId": "108a2000-faa2-40ad-a2dc-f3d03646196e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         40000200  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100)              400       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,081,202\n",
      "Trainable params: 80,802\n",
      "Non-trainable params: 40,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = Input(shape=(None,))                   ## None biểu thị kích thước không xác định của câu\n",
    "\n",
    "embed = Embedding(input_dim=embedding_matrix.shape[0],   ## Khai báo kích thước của vocab\n",
    "                  output_dim=embedding_matrix.shape[1],   ## Khai báo kích thước của embedding\n",
    "                  embeddings_initializer = tf.keras.initializers.Constant(value=embedding_matrix),  ## Khởi tạo cho embedding bằng ma trận có sẵn\n",
    "                  trainable=False,                       ## Không cần thiết train embedding\n",
    "                  mask_zero=True)(inputs)                 ## zero_mask: những vị trí có giá trị 0 không được tính toán, vì đó là giá trị thêm vào cho đủ độ dài mà thôi\n",
    "                                                        ##  (__PADDED_INDEX__ gán bằng 0)\n",
    "\n",
    "lstm = LSTM(units=100,                          ## units: kích thước của hidden_state trong LSTM\n",
    "            return_sequences=False)(embed)      ## return_sequences: LSTM trả về toàn bộ  hay là trả về hidden_state cuối cùng\n",
    "lstm = Dropout(0.2)(lstm)\n",
    "lstm = BatchNormalization()(lstm)\n",
    "outputs = Dense(units=2, \n",
    "              activation='softmax')(lstm)\n",
    "model_lstm1 = Model(inputs=inputs,\n",
    "              outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "model_lstm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nPDauKjmY8UM"
   },
   "outputs": [],
   "source": [
    "list_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FO4v-D93Wxb",
    "outputId": "0690c336-d098-4c92-b4da-ed71884b9ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 8s 33ms/step - loss: 0.4017 - accuracy: 0.8394\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 33ms/step - loss: 0.1295 - accuracy: 0.9641\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.1046 - accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0704 - accuracy: 0.9798\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0664 - accuracy: 0.9794\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0442 - accuracy: 0.9865\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0433 - accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0402 - accuracy: 0.9879\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0253 - accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0291 - accuracy: 0.9919\n",
      "Time:  25.645567306999965\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start = timeit.default_timer() \n",
    "\n",
    "model_lstm1.compile(\n",
    "                optimizer = tf.keras.optimizers.RMSprop(learning_rate= 1e-3, name='RMSprop'),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model_lstm1.fit(X_train, y_train,\n",
    "                    batch_size= 100,\n",
    "                    epochs= 10) \n",
    "     \n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "list_times.append(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vEgXlRG4plmu"
   },
   "outputs": [],
   "source": [
    "performance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJmw5eo4WKCy",
    "outputId": "b17549c7-3ec4-4cd5-9ad5-8bcdc0876670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 0.0546 - accuracy: 0.9821\n",
      "loss và accuracy trên tập test là 0.054580964148044586 0.9820627570152283\n"
     ]
    }
   ],
   "source": [
    "result = model_lstm1.evaluate(X_valid,y_valid)\n",
    "print(\"loss và accuracy trên tập test là {} {}\".format(result[0],result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "SEJMwCH8pn7r"
   },
   "outputs": [],
   "source": [
    "performance.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AjII0JRhnDP",
    "outputId": "33f21bf3-3111-428a-a019-b3b44ea4f4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 100)         40000200  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               [(None, None, 100),       80400     \n",
      "                              (None, 100),                       \n",
      "                              (None, 100)]                       \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 100)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,081,202\n",
      "Trainable params: 80,802\n",
      "Non-trainable params: 40,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(None,))                   \n",
    "embed = Embedding(input_dim=embedding_matrix.shape[0],   \n",
    "                output_dim=embedding_matrix.shape[1],   \n",
    "                  embeddings_initializer = tf.keras.initializers.Constant(value=embedding_matrix),  \n",
    "                  trainable=False,                      \n",
    "                mask_zero=True)(inputs)                \n",
    "                                                        \n",
    "lstm = LSTM(units=100,                         \n",
    "            return_sequences=True,\n",
    "            return_state=True)(embed)     \n",
    "lstm = GlobalAveragePooling1D()(lstm[0])\n",
    "lstm = Dropout(0.2)(lstm)\n",
    "lstm = BatchNormalization()(lstm)\n",
    "outputs = Dense(units=2, activation='softmax')(lstm)\n",
    "\n",
    "model_lstm2 = Model(inputs=inputs,\n",
    "              outputs=outputs)\n",
    "\n",
    "\n",
    "model_lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7CwxrWYHi3k",
    "outputId": "0f2e50ac-c082-4754-8327-10c7e5a52f43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 7s 32ms/step - loss: 0.4294 - accuracy: 0.8246\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 33ms/step - loss: 0.1516 - accuracy: 0.9641\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0956 - accuracy: 0.9738\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0821 - accuracy: 0.9771\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0653 - accuracy: 0.9782\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0602 - accuracy: 0.9814\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0471 - accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 33ms/step - loss: 0.0439 - accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 33ms/step - loss: 0.0354 - accuracy: 0.9906\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0343 - accuracy: 0.9906\n",
      "Time:  25.820473685999787\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer() \n",
    "model_lstm2.compile(\n",
    "                optimizer = tf.keras.optimizers.RMSprop(learning_rate= 1e-3, name='RMSprop'),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model_lstm2.fit(X_train, y_train,\n",
    "                    batch_size= 100,\n",
    "                    epochs= 10) \n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "list_times.append(stop-start)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kg6GeVmPKHPR",
    "outputId": "72898bb1-d661-41be-be10-dce7d591ecad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9776\n",
      "loss và accuracy trên tập val là 0.06356462091207504 0.9775784611701965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = model_lstm2.evaluate(X_valid,y_valid)\n",
    "print(\"loss và accuracy trên tập val là {} {}\".format(result[0],result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "26fFGsXHp8xT"
   },
   "outputs": [],
   "source": [
    "performance.append(result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hfgzk8lIhRZ"
   },
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4gL4ej6xdAT8"
   },
   "outputs": [],
   "source": [
    "list_times1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39dQ8kmaIk-O",
    "outputId": "3834d9f0-d17c-410c-e0f1-28fdf9cb6509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, None, 100)         40000200  \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100)               60600     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,061,402\n",
      "Trainable params: 61,002\n",
      "Non-trainable params: 40,000,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(None,))          \n",
    "embed = Embedding(input_dim=embedding_matrix.shape[0],   \n",
    "                  output_dim=embedding_matrix.shape[1],  \n",
    "                  embeddings_initializer = tf.keras.initializers.Constant(value=embedding_matrix),  \n",
    "                  trainable=False, \n",
    "                  mask_zero=True)(inputs)                \n",
    "                                                    \n",
    "\n",
    "gru = GRU(units=100,                          \n",
    "          return_sequences=False)(embed)      \n",
    "gru = Dropout(0.2)(gru)\n",
    "gru = BatchNormalization()(gru)\n",
    "outputs = Dense(units=2, \n",
    "              activation='softmax')(gru)\n",
    "model_gru1 = Model(inputs=inputs,\n",
    "              outputs=outputs)\n",
    "\n",
    "\n",
    "\n",
    "model_gru1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50vL_GNMJ6Tx",
    "outputId": "42a5fdc0-df52-482b-a058-fbbe8d0ec868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 7s 29ms/step - loss: 0.5053 - accuracy: 0.7614\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.1858 - accuracy: 0.9493\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0934 - accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0763 - accuracy: 0.9794\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0602 - accuracy: 0.9827\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0472 - accuracy: 0.9868\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 0.0381 - accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0320 - accuracy: 0.9915\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0285 - accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 28ms/step - loss: 0.0221 - accuracy: 0.9928\n",
      "Time:  25.379942895000113\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "model_gru1.compile(\n",
    "                optimizer = tf.keras.optimizers.RMSprop(learning_rate= 1e-3, name='RMSprop'),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model_gru1.fit(X_train, y_train,\n",
    "                    batch_size= 100,\n",
    "                    epochs= 10) \n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "list_times1.append(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "SHknNxEWqBpy"
   },
   "outputs": [],
   "source": [
    "performance1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IdZCFoCKCqN",
    "outputId": "c66a8ca2-9e6c-43b3-db4b-5018651a1ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9749\n",
      "loss và accuracy trên tập val là 0.08184133470058441 0.9748879075050354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = model_gru1.evaluate(X_valid,y_valid)\n",
    "print(\"loss và accuracy trên tập val là {} {}\".format(result[0],result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "NbyFDp1sqDxr"
   },
   "outputs": [],
   "source": [
    "performance1.append(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imqg7BC2MxrQ",
    "outputId": "79219262-c8a6-46d4-989e-88ae6a494b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, None, 100) dtype=float32 (created by layer 'gru_1')>, <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'gru_1')>]\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 100)         40000200  \n",
      "                                                                 \n",
      " gru_1 (GRU)                 [(None, None, 100),       60600     \n",
      "                              (None, 100)]                       \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 100)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,061,402\n",
      "Trainable params: 40,061,202\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = Input(shape=(None,))          \n",
    "embed = Embedding(input_dim=embedding_matrix.shape[0],   \n",
    "                  output_dim=embedding_matrix.shape[1],  \n",
    "                  embeddings_initializer = tf.keras.initializers.Constant(value=embedding_matrix),  \n",
    "                  mask_zero=True)(inputs)                \n",
    "                                                    \n",
    "\n",
    "gru = GRU(units=100,                         \n",
    "            return_sequences=True,\n",
    "            return_state=True)(embed)     \n",
    "print(gru)\n",
    "gru = GlobalAveragePooling1D()(gru[0])\n",
    "gru = Dropout(0.2)(gru)\n",
    "gru = BatchNormalization()(gru)\n",
    "outputs = Dense(units=2, activation='softmax')(gru)\n",
    "model_gru2 = Model(inputs=inputs,\n",
    "              outputs=outputs)\n",
    "\n",
    "\n",
    "model_gru2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUUSVuWGNN_C",
    "outputId": "f838734e-6053-40eb-ebeb-23b9094801c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 7s 40ms/step - loss: 0.4861 - accuracy: 0.7661\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 2s 38ms/step - loss: 0.1933 - accuracy: 0.9437\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 2s 37ms/step - loss: 0.0836 - accuracy: 0.9823\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 2s 36ms/step - loss: 0.0581 - accuracy: 0.9834\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0375 - accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0274 - accuracy: 0.9922\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0225 - accuracy: 0.9930\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0189 - accuracy: 0.9944\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0146 - accuracy: 0.9951\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 2s 35ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "Time:  21.86582246099988\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "model_gru2.compile(\n",
    "                optimizer = tf.keras.optimizers.RMSprop(learning_rate= 1e-3, name='RMSprop'),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model_gru2.fit(X_train, y_train,\n",
    "                    batch_size= 100,\n",
    "                    epochs= 10) \n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "list_times1.append(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSoT8oucC4S1",
    "outputId": "54b7505e-fdce-447c-f335-0422fdb989b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0724 - accuracy: 0.9812\n",
      "loss và accuracy trên tập val là 0.07236023247241974 0.9811659455299377\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = model_gru2.evaluate(X_valid,y_valid)\n",
    "print(\"loss và accuracy trên tập val là {} {}\".format(result[0],result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "r0FVpMIiqMe8"
   },
   "outputs": [],
   "source": [
    "performance1.append(result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8hM2Wh93PYd"
   },
   "source": [
    "\n",
    "#### 2. So sánh giữa 2 cấu trúc của GRU và LSTM. Từ đó đưa ra kết luận của mình (có dẫn chứng )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6DG-Z1LJMFm"
   },
   "source": [
    "**Công thức GRU và LSTM**\n",
    "\n",
    "**LSTM Unit**\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Forget gate} \\\\\n",
    "f_{t} &= \\sigma \\left(W_{f}.\\left[h_{t-1} , x_{t}\\right]+b_{f}\\right) \\\\\n",
    "\\text{Input gate} \\\\\n",
    "i_{t} &= \\sigma\\left(W_{i}.\\left[h_{t-1},x_{t} \\right] + b_{i} \\right) \\\\\n",
    "\\bar{C}_{t} &=\\tanh\\left(W_{c}.\\left[h_{t-1}, x_{t}\\right]+b_{C}\\right) \\\\\n",
    "C_{t} &=f_{t} * C_{t-1}+ i_{t}* \\bar{C}_{t-1} \\\\\n",
    "\\text{Output gate} \\\\\n",
    "o_{t} &=\\sigma \\left(W_{o}.\\left[h_{t-1},x_{t}\\right] + b_{o}\\right) \\\\  \n",
    "h_{t} &= o_{t} * \\tanh\\left(C_t\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**GRU Unit**\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Update gate} \\\\\n",
    "&z_{t}=\\sigma\\left(W_{z} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\\\\n",
    "\\text{Reset gate} \\\\\n",
    "&r_{t}=\\sigma\\left(W_{r} \\cdot\\left[h_{t-1}, x_{t}\\right]\\right) \\\\\n",
    "&\\tilde{h}_{t}=\\tanh \\left(W \\cdot\\left[r_{t} * h_{t-1}, x_{t}\\right]\\right) \\\\\n",
    "&h_{t}=\\left(1-z_{t}\\right) * h_{t-1}+z_{t} * \\tilde{h}_{t}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Đối với **LSTM**, ta thấy rằng nó có tới 3 cổng là cổng đầu vào $i$, cổng quên $f$ và cổng đầu ra $o$ , trong khi **GRU** chỉ có 2 là cổng thiết lập lại $r$ và cổng cập nhật $z$. Nhìn vào kiến trúc của **LSTM** và **GRU** thì ta thấy rằng **LSTM** có phần phức tạp hơn do đó lượng parameters cần cho mô hình này sẽ nhiều hơn so với **GRU**.\n",
    "\n",
    "Để so sánh giữa 2 mô hình này thì ta vẫn chưa đánh giá được bên nào nhỉnh hơn và cần phải chạy thử mới biết. Nhưng vẫn có 1 số trường hợp nếu ta muốn tìm ra kết quả nhanh hơn hay lượng dữ liệu hiện có bị ít thì **GRU** sẽ được ưu tiên chọn trước vì lượng parameters của nó ít hơn **LSTM**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "jOsOEsGoJN14",
    "outputId": "7a658aad-fe14-45ea-db84-a4c0b07d26c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thời gian chạy của mô hình sử dụng LSTM và sử dụng GRU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.645567</td>\n",
       "      <td>25.379943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.820474</td>\n",
       "      <td>21.865822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LSTM        GRU\n",
       "0  25.645567  25.379943\n",
       "1  25.820474  21.865822"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_times = {\n",
    "  \"LSTM\": list_times,\n",
    "  \"GRU\": list_times1\n",
    "}\n",
    "\n",
    "print('Thời gian chạy của mô hình sử dụng LSTM và sử dụng GRU')\n",
    "df = pd.DataFrame(data_times)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "0Daa7fQTqTOy",
    "outputId": "6dc4f06e-8aa4-4fbd-a303-f6e06eaf4255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance của mô hình sử dụng LSTM và sử dụng GRU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM</th>\n",
       "      <th>GRU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.974888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.981166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LSTM       GRU\n",
       "0  0.982063  0.974888\n",
       "1  0.977578  0.981166"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances = {\n",
    "  \"LSTM\": performance,\n",
    "  \"GRU\": performance1\n",
    "}\n",
    "\n",
    "print('Performance của mô hình sử dụng LSTM và sử dụng GRU')\n",
    "df = pd.DataFrame(performances)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZenvToxF_5u"
   },
   "source": [
    "Với dữ liệu trên thì ta thấy rằng **LSTM** và **GRU** có performance tương đối ngang nhau và kết quả tốt nhất thuộc về **LSTM** nhưng xét về lượng thời gian chạy và số parameters thì **GRU** tốt hơn **LSTM** ở khía cạnh này. Vì vậy đối với data này , nếu ta muốn có kết quả tốt hơn thì chọn **LSTM**, còn nếu ta ưu tiên thời gian hơn thì sẽ chọn **GRU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rwSLSpEF9S3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MHNC_TH5_18110095.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
