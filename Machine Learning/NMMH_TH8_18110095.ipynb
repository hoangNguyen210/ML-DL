{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vgbh14dJOTDX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4a-EZhD7Oy8_"
   },
   "outputs": [],
   "source": [
    "def one_hot_vector(y):\n",
    "    out = np.zeros((y.shape[0], max(y)+1))\n",
    "    for i in range(y.shape[0]):\n",
    "        out[i, y[i]] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6hfE2auOsii",
    "outputId": "e3c9ca36-eeeb-422b-8937-bf1ec2ba966a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24889612,  0.74760804],\n",
       "       [-0.74985907,  0.44945807],\n",
       "       [-0.5145559 , -0.91335007],\n",
       "       ...,\n",
       "       [ 0.61938387,  1.6949654 ],\n",
       "       [ 0.93715397,  0.24593182],\n",
       "       [ 1.31587098,  0.87455223]])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_train.csv\")\n",
    "valid = pd.read_csv(\"https://raw.githubusercontent.com/huynhthanh98/ML/master/lab-08/bt_valid.csv\")\n",
    "\n",
    "x1_train = train[\"x1\"].values\n",
    "x2_train = train[\"x2\"].values\n",
    "y_train = train[\"label\"].values\n",
    "\n",
    "x1_valid = valid['x1'].values\n",
    "x2_valid = valid['x2'].values\n",
    "y_valid = valid['label'].values\n",
    "\n",
    "# normalize\n",
    "x1_mean = np.mean(x1_train)\n",
    "x1_std = np.std(x1_train)\n",
    "x2_mean = np.mean(x2_train)\n",
    "x2_std = np.std(x2_train)\n",
    "\n",
    "x1_train = (x1_train - x1_mean)/ x1_std\n",
    "x2_train = (x2_train - x2_mean)/ x2_std\n",
    "\n",
    "x1_valid = (x1_valid - x1_mean)/ x1_std\n",
    "x2_valid = (x2_valid - x2_mean)/ x2_std\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.concatenate([x1_train.reshape(-1,1), x2_train.reshape(-1,1)], axis=1)\n",
    "y_train_onehot = one_hot_vector(y_train)\n",
    "\n",
    "X_valid = np.concatenate([x1_valid.reshape(-1,1), x2_valid.reshape(-1,1)], axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5olO6EpvQXX7"
   },
   "source": [
    "###  1. Từ code demo hãy cài đặt thêm một module để chọn ra được bộ weights sao cho accuracy trên tập validation là tốt nhất.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "31gScN5bOwJt"
   },
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \n",
    "    return np.maximum(0,Z)\n",
    "def d_relu(Z):\n",
    "    # tính đạo hàm cho hàm Relu\n",
    "    return 1*(Z > 0) \n",
    "\n",
    "def softmax(Z):\n",
    "    return np.exp(Z)/ np.sum(np.exp(Z), axis = 0)\n",
    "\n",
    "def accuracy(y_hat,y_true) :\n",
    "    return np.sum(y_hat.argmax(axis = 0) == y_true) / len(y_true)\n",
    "\n",
    "def loss(y_hat, y_true) :\n",
    "    # tính cross entropy loss cho mỗi vòng epochs\n",
    "    return np.sum(-y_true * np.log(y_hat.T))/y_true.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW3jIrP4tzlf"
   },
   "source": [
    "Khởi tạo $L$ layers trong mạng neuron, ta sẽ cập nhật các layers theo công thức sau.\n",
    "\n",
    "**Forward :** \n",
    "  \\begin{align*}\n",
    "    Z^{[l]} &= W^{[l]}A^{[l-1]} + B^{[l]}   \\\\\n",
    "    A^{[l]} &= Relu(Z^{[l]})  \\\\\n",
    "    \\text{với  } l &\\in [0,L - 1]\n",
    "  \\end{align*}\n",
    "\n",
    " $Z$ là lớp tuyến tính , $A$ là lớp kích hoạt\n",
    "\n",
    " Ở layer thứ 0 là giá trị đầu vào nên $A^{[0]} = X$\n",
    "\n",
    " Ở layer cuối cùng , ta sẽ cập nhật $A^{[L]}$ bằng hàm softmax : $A^{[L]} = softmax(Z^{[L]})$\n",
    "\n",
    "Trong đó $W^{[l]}$ và $B^{[l]}$ là các tham số weight và biases ứng với layer $l$ \n",
    "\n",
    "**Backward** :\n",
    "\n",
    "  \\begin{align*}\n",
    "    dZ^{[l]}&= dA^{[l]} * relu'(Z^{[l]}) \\\\\n",
    "    dW^{[l]} &= \\dfrac{1}{m} dZ^{[l]} A^{[l-1]T}  \\\\\n",
    "    dB^{[l]} &= \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}dZ^{[l](i)} \\\\\n",
    "    dA^{[l-1]} &= W^{[l]T}dZ^{[l]} \\\\\n",
    "    \\text{với  } l &\\in [0,L - 1]\n",
    "  \\end{align*}\n",
    "\n",
    "Trong đó $m$ là số sample , $(i)$ là sample thứ i\n",
    "\n",
    "Ở layer cuối cùng , $dZ^{[L]} = A^{[L]} - Y $ \\\\\n",
    "Ở layer đầu tiên  , $dZ^{[1]} = dA^{[1]} * relu'(X)$\n",
    "\n",
    "Sau khi **forward** và **backward** ta sẽ cập nhật cho $W$ và $B$ bằng **Gradient Descent** :\n",
    "\n",
    "\\begin{cases}\n",
    "  W^{[l]}  &:=   W^{[l]} - \\alpha *  dW^{[l]} \\\\\n",
    "  B^{[l]}  &:=   B^{[l]} - \\alpha *  dB^{[l]}  \\\\\n",
    "\\end{cases}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eHl_Zh53O8fL"
   },
   "outputs": [],
   "source": [
    "class Neural_Net :\n",
    "  \n",
    "  def __init__ (self, n_layers , list_N_L):\n",
    "\n",
    "    '''\n",
    "    Tham số :\n",
    "    n_layers -- Số hidden layers khởi tạo\n",
    "    list_N_L -- List các số neuron tương ứng với layers khởi tạo  \n",
    "    '''\n",
    "    assert n_layers == len(list_N_L)\n",
    "    self.n_layers = n_layers\n",
    "    self.list_N_L = list_N_L\n",
    "  \n",
    "  def fit (self, X_train , y_train , n_epochs , lr ) :\n",
    "    '''\n",
    "    Tìm ra bộ Weight và bias tốt nhất trên tập train \n",
    "    Tham số :\n",
    "    X_train -- Dữ liệu cần train\n",
    "    y_train -- Label của tập train\n",
    "    n_epochs -- Số epoch để chạy  \n",
    "    lr   -- tốc độ học\n",
    "    '''\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train \n",
    "    caches_update_para = []\n",
    "    self.y_train_onehot = one_hot_vector(y_train)\n",
    "    cache_init_parameter  = self._init_para()\n",
    "\n",
    "    A_L , forward_caches = self._forward(cache_init_parameter , self.X_train)\n",
    "    backward_caches = self._backward(A_L,forward_caches)\n",
    "\n",
    "    print('Epoch 1 :    ---------- Loss : {:.7f}------------ Accuracy : {:.7f}'.format(loss(A_L,self.y_train_onehot) , accuracy(A_L, self.y_train) ))\n",
    "    update_para = self._update_par(forward_caches, backward_caches , lr)\n",
    "\n",
    "    caches_update_para.append(update_para)\n",
    "    for i in range(2, n_epochs + 1) :\n",
    "        A_L1 , forward_caches1 = self._forward(update_para , self.X_train)\n",
    "        if i % 1000 == 0 :\n",
    "          print('Epoch {} : ---------- Loss : {:.7f}------------ Accuracy : {:.7f}'.format(i, loss(A_L1,self.y_train_onehot) , accuracy(A_L1, y_train)))\n",
    "        backward_caches1 =  self._backward(A_L1,forward_caches1)\n",
    "        update_para = self._update_par(forward_caches1, backward_caches1 , lr)\n",
    "        caches_update_para.append(update_para)\n",
    "    self.update_para = caches_update_para[-2]\n",
    "    \n",
    "  def summary(self ,X_train ,  y_train) :\n",
    "    '''\n",
    "    Mô ta các kích thước và số tham số của mô hình \n",
    "    Tham số :\n",
    "    X_train -- Dữ liệu cần train\n",
    "    y_train -- Label của tập train\n",
    "    '''\n",
    "    n_samples = X_train.shape[0]\n",
    "    input_feature = [X_train.shape[1]]\n",
    "    output_class = [len(np.unique(y_train))]\n",
    "    list_para = input_feature +  self.list_N_L + output_class\n",
    "    count_para = 0\n",
    "    print('Cấu trúc model : ')\n",
    "    print()\n",
    "    print('Số sample : {}'.format(n_samples))\n",
    "    print('Số feature : {}'.format(input_feature[0]))\n",
    "    print('_'*65)\n",
    "    print('Layer (type) \\t \\t \\t Output shape \\t \\tParam # '  )\n",
    "    print('='*65)\n",
    "    for i in range(len(list_para) - 2 ) :\n",
    "      print('_'*65)\n",
    "      current_para = list_para[i]*list_para[i+1]+list_para[i+1] \n",
    "      print('dense_{} (Dense) \\t \\t (None,{}) \\t \\t {}'.format(i+1,self.list_N_L[i],current_para))\n",
    "      count_para += current_para\n",
    "    print('_'*65)\n",
    "    current_para = list_para[-2]*list_para[-2+1]+list_para[-2+1]\n",
    "    count_para += current_para\n",
    "    print('dense_{} (Dense) \\t \\t (None,{}) \\t \\t {}'.format(self.n_layers +1,output_class[0],current_para))\n",
    "    print('='*65)\n",
    "    print('Total params : {}'.format(count_para))\n",
    "    print('Trainable params : {}'.format(count_para))\n",
    "    print('Non-trainable params: 0')\n",
    "    print('_'*65)\n",
    "\n",
    "  def predict(self, X_test) :\n",
    "    '''\n",
    "    Tham số :\n",
    "    X_test -- Dữ liệu test\n",
    "    Return :\n",
    "    Trả về label dự đoán của tập test \n",
    "    '''\n",
    "    self.A_L = self._forward(self.update_para, X_test)\n",
    "    return self.A_L.argmax(axis = 0)\n",
    "\n",
    "  def accuracy(self,X_test , y_test) :\n",
    "    '''\n",
    "    Tham số :\n",
    "    X_test -- Dữ liệu test\n",
    "    y_test -- Label của tập test\n",
    "    Return : \n",
    "    Trả về accuracy giữa label dự đoán và label thực tế\n",
    "    '''\n",
    "    A_L , forward_caches  = self._forward(self.update_para  , X_test)\n",
    "    return np.sum(A_L.argmax(axis = 0)  == y_test) / len(y_test)\n",
    "\n",
    "  def _init_para (self):\n",
    "    '''\n",
    "    Khởi tạo các tham số cho Epoch đầu tiên\n",
    "\n",
    "    Return :\n",
    "    Hàm trả về một list bao gồm các tuple chứa (W,b) cho từng lớp layers\n",
    "    '''\n",
    "    np.random.seed(3)\n",
    "    N_0 = self.X_train.shape[1]\n",
    "    cache_init_parameter = [] # biến lưu các tham số\n",
    "    # tạo tham số cho layer đầu tiên\n",
    "    W = 0.1 * np.random.rand(self.list_N_L[0], N_0)\n",
    "    b = np.zeros((self.list_N_L[0],1))\n",
    "    cache_init_parameter.append((W,b))\n",
    "    \n",
    "    # tạo tham số cho các hidden layers\n",
    "    for i in range(1, self.n_layers) :\n",
    "        W = 0.1 * np.random.rand(self.list_N_L[i] , self.list_N_L[i-1])\n",
    "        b = np.zeros((self.list_N_L[i],1))\n",
    "        cache_init_parameter.append((W,b))\n",
    "        \n",
    "    # tạo tham số cho layer cuối cùng    \n",
    "    n_classes = len(np.unique(self.y_train))    \n",
    "    W = 0.1 * np.random.rand( n_classes , self.list_N_L[-1])\n",
    "    b = np.zeros((n_classes,1) )\n",
    "    cache_init_parameter.append((W,b))\n",
    "    return cache_init_parameter\n",
    "\n",
    "  def _forward(self, caches_parameter , X_train) :\n",
    "    '''\n",
    "    Tính lan truyền xuôi từ input đầu vào \n",
    "    Tham số :\n",
    "    caches_parameter : list chứa các (W,b) cho từng layers\n",
    "    X_train : Dữ liệu train\n",
    "\n",
    "    Return :\n",
    "    Trả về A_L ở layer cuối cùng và một list gồm các tham số (W,b,Z) tương ứng với mỗi layer\n",
    "    '''\n",
    "    forward_caches = [] # list lưu trữ các biến (W,b,Z)\n",
    "    # forward đối với layer Input\n",
    "    Z_1 = caches_parameter[0][0] @ X_train.T + caches_parameter[0][1]\n",
    "    A_prev = relu(Z_1)\n",
    "    forward_caches.append((caches_parameter[0][0] , caches_parameter[0][1] , Z_1 ))\n",
    "    # forward giữa các hidden layers\n",
    "    L = len(caches_parameter)\n",
    "    for l in range(1, L - 1) :\n",
    "        Z_l = caches_parameter[l][0] @ A_prev + caches_parameter[l][1]\n",
    "        forward_caches.append((caches_parameter[l][0] ,  caches_parameter[l][1] , Z_l))\n",
    "        A_prev = relu(Z_l)\n",
    "    # forward ở layer cuối cùng     \n",
    "    Z_L = caches_parameter[-1][0] @ A_prev + caches_parameter[-1][1]\n",
    "    forward_caches.append((caches_parameter[-1][0] ,  caches_parameter[-1][1] , Z_L))\n",
    "    A_prev = softmax(Z_L)\n",
    "    \n",
    "    return  A_prev , forward_caches\n",
    "\n",
    "\n",
    "  def _backward(self, A_L , caches) :\n",
    "    '''\n",
    "    Tính lan truyền ngược  \n",
    "    Tham số :\n",
    "    A_L : A_L ở layer cuối cùng ở bước forward\n",
    "    caches : list gồm các tham số (W,b,Z) ở các layer tương ứng tính được ở bước forward \n",
    "    Return :\n",
    "    Trả về list gồm các (dW,db) ở các layer tương ứng được dùng để cập nhật cho các tham số (W,b)\n",
    "    '''\n",
    "    m = len(self.y_train)\n",
    "    d_caches = []\n",
    "    y_train_onehot = one_hot_vector(self.y_train)\n",
    "\n",
    "    # backward layer cuối cùng\n",
    "    d_Z_L  = A_L - y_train_onehot.T\n",
    "    d_W_L  = 1/m * d_Z_L @ relu(caches[-2][2]).T\n",
    "    d_b_L  = 1/m * np.sum(d_Z_L , axis = 1 , keepdims = True)\n",
    "    d_A_prev = caches[-1][0].T @ d_Z_L \n",
    "    d_caches.append((d_W_L,d_b_L))\n",
    "    # backward giữa các hidden layers\n",
    "    L = len(caches)\n",
    "    for i in range(L-2 , 0 , -1) :\n",
    "        d_Z = d_A_prev * d_relu(caches[i][2])\n",
    "        d_W = 1/m * d_Z @ relu(caches[i-1][2].T)\n",
    "        d_b = 1/m * np.sum(d_Z , axis = 1 , keepdims = True)\n",
    "        d_caches.append((d_W,d_b))\n",
    "        d_A_prev = caches[i][0].T @ d_Z \n",
    "    # backward ở layer Input\n",
    "    d_Z = d_A_prev * d_relu(caches[0][2])\n",
    "    d_W = 1/m * d_Z @ X_train\n",
    "    d_b = 1/m * np.sum(d_Z , axis = 1 , keepdims = True)\n",
    "    d_caches.append((d_W,d_b))\n",
    "\n",
    "    return d_caches[::-1]    \n",
    "\n",
    "  def _update_par (self, caches, d_caches , lr) :\n",
    "    '''\n",
    "    Cập nhật các parameter sau mỗi epoch \n",
    "    Tham số :\n",
    "    caches : list chứa các (W,b,Z) cho từng layers ở bước forward\n",
    "    d_caches :  list chứa các (dW,db) cho từng layers ở bước backward\n",
    "    Return :\n",
    "    Trả về list các (W,b) vừa được cập nhật \n",
    "    '''\n",
    "    assert len(caches) == len(d_caches)\n",
    "    new_para = []\n",
    "    for i in range(len(caches)) :\n",
    "        new_W = caches[i][0] - lr* d_caches[i][0]\n",
    "        new_b = caches[i][1] - lr* d_caches[i][1]\n",
    "        new_para.append((new_W , new_b))\n",
    "    return new_para\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSzRmz7mPFKh",
    "outputId": "dc35ccec-b7ff-48a6-c15e-b34cae92db41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu trúc model : \n",
      "\n",
      "Số sample : 900\n",
      "Số feature : 2\n",
      "_________________________________________________________________\n",
      "Layer (type) \t \t \t Output shape \t \tParam # \n",
      "=================================================================\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense) \t \t (None,3) \t \t 9\n",
      "_________________________________________________________________\n",
      "dense_2 (Dense) \t \t (None,4) \t \t 16\n",
      "_________________________________________________________________\n",
      "dense_3 (Dense) \t \t (None,5) \t \t 25\n",
      "_________________________________________________________________\n",
      "dense_4 (Dense) \t \t (None,3) \t \t 18\n",
      "=================================================================\n",
      "Total params : 68\n",
      "Trainable params : 68\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Neural_Net(3,[3,4,5])\n",
    "# ở đây ta sẽ chọn 3 hidden layers mỗi layers có số neuron lần lượt là 3 ,4, 5 và layers là softmax để phân loại 3 class\n",
    "model.summary(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGlDV30FpxDJ",
    "outputId": "166ebaaa-b031-4b47-8580-80c379c23cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 :    ---------- Loss : 1.0986584------------ Accuracy : 0.2455556\n",
      "Epoch 1000 : ---------- Loss : 0.4174864------------ Accuracy : 0.8733333\n",
      "Epoch 2000 : ---------- Loss : 0.3545076------------ Accuracy : 0.8844444\n",
      "Epoch 3000 : ---------- Loss : 0.2704845------------ Accuracy : 0.9000000\n",
      "Epoch 4000 : ---------- Loss : 0.2693621------------ Accuracy : 0.8988889\n",
      "Epoch 5000 : ---------- Loss : 0.2690592------------ Accuracy : 0.8988889\n",
      "Epoch 6000 : ---------- Loss : 0.2580326------------ Accuracy : 0.9033333\n",
      "Epoch 7000 : ---------- Loss : 0.2576201------------ Accuracy : 0.9022222\n",
      "Epoch 8000 : ---------- Loss : 0.2574660------------ Accuracy : 0.9022222\n",
      "Epoch 9000 : ---------- Loss : 0.2574036------------ Accuracy : 0.9033333\n",
      "Epoch 10000 : ---------- Loss : 0.2573486------------ Accuracy : 0.9033333\n",
      "Epoch 11000 : ---------- Loss : 0.2573101------------ Accuracy : 0.9033333\n",
      "Epoch 12000 : ---------- Loss : 0.2572700------------ Accuracy : 0.9033333\n",
      "Epoch 13000 : ---------- Loss : 0.2572518------------ Accuracy : 0.9033333\n",
      "Epoch 14000 : ---------- Loss : 0.2572329------------ Accuracy : 0.9033333\n",
      "Epoch 15000 : ---------- Loss : 0.2572253------------ Accuracy : 0.9033333\n",
      "Epoch 16000 : ---------- Loss : 0.2572189------------ Accuracy : 0.9033333\n",
      "Epoch 17000 : ---------- Loss : 0.2572161------------ Accuracy : 0.9033333\n",
      "Epoch 18000 : ---------- Loss : 0.2572113------------ Accuracy : 0.9033333\n",
      "Epoch 19000 : ---------- Loss : 0.2572076------------ Accuracy : 0.9033333\n",
      "Epoch 20000 : ---------- Loss : 0.2568588------------ Accuracy : 0.9011111\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train , 20000, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spTdh9eTPIlD",
    "outputId": "b67749b6-55f4-4ba4-8c00-8425d8b9457f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trên tập valid :  0.64\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy trên tập valid : ',model.accuracy(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7WZeDzqQeja"
   },
   "source": [
    "### 2. Từ bộ dữ liệu bên dưới hãy cài  đặt backpropagation cho bài toán phân biệt ung thư vú. Hãy tự chọn số layers và số nodes mà mình cho là thích hợp, cũng như là nêu ra số layers và số nodes của mỗi layer mà mình đã chọn. Tính accuracy trên tập training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZoAt96LhPYjO"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = breast_cancer.data  \n",
    "y = breast_cancer.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split( X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_mean=np.mean(X_train)\n",
    "X_std=np.std(X_train)\n",
    "\n",
    "X_valid=(X_valid-X_mean)/X_std\n",
    "X_train=(X_train-X_mean)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjzcW5BiPj3R",
    "outputId": "44899c0b-21b3-413d-87e5-715b75ddd245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu trúc model : \n",
      "\n",
      "Số sample : 455\n",
      "Số feature : 30\n",
      "_________________________________________________________________\n",
      "Layer (type) \t \t \t Output shape \t \tParam # \n",
      "=================================================================\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense) \t \t (None,2) \t \t 62\n",
      "_________________________________________________________________\n",
      "dense_2 (Dense) \t \t (None,2) \t \t 6\n",
      "_________________________________________________________________\n",
      "dense_3 (Dense) \t \t (None,2) \t \t 6\n",
      "_________________________________________________________________\n",
      "dense_4 (Dense) \t \t (None,2) \t \t 6\n",
      "_________________________________________________________________\n",
      "dense_5 (Dense) \t \t (None,2) \t \t 6\n",
      "=================================================================\n",
      "Total params : 86\n",
      "Trainable params : 86\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Neural_Net(4,[2,2,2,2])\n",
    "# ở đây ta sẽ chọn 4 hidden layers mỗi layers có 2 neurons và layer cuối cùng là layer softmax để phân loại 2 class\n",
    "model.summary(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkmH3vgcnQss",
    "outputId": "0cf07ae9-ffd6-478c-b7cd-a678f37100e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 :    ---------- Loss : 0.6931463------------ Accuracy : 0.3626374\n",
      "Epoch 1000 : ---------- Loss : 0.6549190------------ Accuracy : 0.6373626\n",
      "Epoch 2000 : ---------- Loss : 0.6549182------------ Accuracy : 0.6373626\n",
      "Epoch 3000 : ---------- Loss : 0.6549167------------ Accuracy : 0.6373626\n",
      "Epoch 4000 : ---------- Loss : 0.6549133------------ Accuracy : 0.6373626\n",
      "Epoch 5000 : ---------- Loss : 0.6549037------------ Accuracy : 0.6373626\n",
      "Epoch 6000 : ---------- Loss : 0.6548495------------ Accuracy : 0.6373626\n",
      "Epoch 7000 : ---------- Loss : 0.2273435------------ Accuracy : 0.9098901\n",
      "Epoch 8000 : ---------- Loss : 0.1668665------------ Accuracy : 0.9230769\n",
      "Epoch 9000 : ---------- Loss : 0.1635580------------ Accuracy : 0.9340659\n",
      "Epoch 10000 : ---------- Loss : 0.1592793------------ Accuracy : 0.9340659\n",
      "Epoch 11000 : ---------- Loss : 0.1557558------------ Accuracy : 0.9318681\n",
      "Epoch 12000 : ---------- Loss : 0.1525407------------ Accuracy : 0.9340659\n",
      "Epoch 13000 : ---------- Loss : 0.1495313------------ Accuracy : 0.9362637\n",
      "Epoch 14000 : ---------- Loss : 0.1468909------------ Accuracy : 0.9384615\n",
      "Epoch 15000 : ---------- Loss : 0.1445288------------ Accuracy : 0.9384615\n",
      "Epoch 16000 : ---------- Loss : 0.1423012------------ Accuracy : 0.9406593\n",
      "Epoch 17000 : ---------- Loss : 0.1403008------------ Accuracy : 0.9428571\n",
      "Epoch 18000 : ---------- Loss : 0.1384973------------ Accuracy : 0.9450549\n",
      "Epoch 19000 : ---------- Loss : 0.1368141------------ Accuracy : 0.9450549\n",
      "Epoch 20000 : ---------- Loss : 0.1352422------------ Accuracy : 0.9450549\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train , 20000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfW31LO9Pnow",
    "outputId": "47d76c32-df12-4f89-cfce-b9a2c8207cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trên tập train :  0.945054945054945\n",
      "Accuracy trên tập valid :  0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy trên tập train : ',model.accuracy(X_train, y_train))\n",
    "print('Accuracy trên tập valid : ',model.accuracy(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NMMH_TH8_18110095.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
